{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1Z7qsFlc7W9BEPWQwgUKZtNVmoTsOB16y",
      "authorship_tag": "ABX9TyM3Os42OrASQ7pfIIS5zaHU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rito43/Rito43/blob/main/M23CSA021_iris_datset_Q2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aiFkV9R1mmMB",
        "outputId": "091f7094-60c6-4613-cef0-2d307565ea83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KGblaGcpeuFr"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Path to your file\n",
        "file_path = '/content/drive/MyDrive/hymenoptera_data '\n",
        "\n",
        "# Get the directory of the file\n",
        "directory = os.path.dirname(file_path)\n",
        "\n",
        "print(\"Directory of the file:\", directory)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "qS2ohD-ae0rH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import transforms\n",
        "from skimage import io\n",
        "import os\n",
        "\n",
        "import os\n",
        "from skimage import io\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class CustomHymenopteraDataset(Dataset):\n",
        "    def __init__(self, root_dir, subset='train', transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.subset = subset\n",
        "        self.transform = transform\n",
        "        self.images, self.labels = self._load_images_and_labels()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.images[idx]\n",
        "        image = io.imread(img_path)\n",
        "        label = self.labels[idx]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, label\n",
        "\n",
        "    def _load_images_and_labels(self):\n",
        "        images = []\n",
        "        labels = []\n",
        "        subset_dir = os.path.join(self.root_dir, self.subset)\n",
        "        for subdir in os.listdir(subset_dir):\n",
        "            subdir_path = os.path.join(subset_dir, subdir)\n",
        "            if os.path.isdir(subdir_path):\n",
        "                for filename in os.listdir(subdir_path):\n",
        "                    file_path = os.path.join(subdir_path, filename)\n",
        "                    if os.path.isfile(file_path) and not filename.startswith('.'):\n",
        "                        images.append(file_path)\n",
        "                        labels.append(subdir)  # Use the folder name as the label\n",
        "        return images, labels\n",
        "\n",
        "\n",
        "# Define transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "# Define the root directory where the images are stored\n",
        "root_dir = '/content/drive/MyDrive/hymenoptera_data'\n",
        "\n",
        "# Create CustomHymenopteraDataset instances for train and test datasets\n",
        "train_dataset = CustomHymenopteraDataset(root_dir=root_dir, subset='train', transform=transform)\n",
        "test_dataset = CustomHymenopteraDataset(root_dir=root_dir, subset='val', transform=transform)\n",
        "\n",
        "# Create DataLoader instances for train and test datasets\n",
        "train_batch_size = 64\n",
        "test_batch_size = 32\n",
        "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=train_batch_size, shuffle=True)\n",
        "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=test_batch_size, shuffle=False)\n"
      ],
      "metadata": {
        "id": "of63G-xMe3ur"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.decomposition import PCA\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
        "from sklearn.metrics import mean_squared_error as mse\n",
        "from sklearn.metrics import mean_squared_log_error as msle\n",
        "from sklearn.metrics import mean_absolute_error as mae\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from sklearn.datasets import fetch_openml\n",
        "import numpy as np\n",
        "from skimage.color import rgb2lab, lab2rgb\n",
        "\n",
        "\n",
        "# Define the CAE architecture\n",
        "class CAELABTORGB(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CAELABTORGB, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(3, 16, kernel_size=3, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Conv2d(16, 32, kernel_size=3, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.LeakyReLU(0.2),\n",
        "        )\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.ConvTranspose2d(32, 16, kernel_size=4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(16, 3, kernel_size=4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(3),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        x = self.decoder(x)\n",
        "        return x\n",
        "\n",
        "# Initialize CAE model\n",
        "model_lab_to_rgb = CAELABTORGB()\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model_lab_to_rgb.parameters(), lr=0.001)\n",
        "\n",
        "# Train the CAE model\n",
        "num_epochs = 20\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for images,_ in train_dataloader:\n",
        "        # Zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "        images_lab = rgb2lab(images.permute(0, 2, 3, 1))\n",
        "        images_lab_tensor = torch.tensor(images_lab.transpose(0,3,1,2), dtype=torch.float32)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model_lab_to_rgb(images_lab_tensor)\n",
        "\n",
        "        # Compute the loss\n",
        "        loss = criterion(outputs, images)\n",
        "\n",
        "        # Backward pass and optimize\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "\n",
        "\n",
        "    epoch_loss = running_loss / len(train_dataloader)\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f},')\n"
      ],
      "metadata": {
        "id": "mv42AxXIe8uj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from skimage.color import rgb2lab, lab2rgb\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
        "\n",
        "# Define evaluation function\n",
        "def evaluate(model, dataloader):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for images,_ in dataloader:\n",
        "            images_lab = rgb2lab(images.permute(0, 2, 3, 1))\n",
        "            images_lab_tensor = torch.tensor(images_lab.transpose(0,3,1,2), dtype=torch.float32)\n",
        "            outputs_rgb_tensor = model(images_lab_tensor)\n",
        "            outputs_rgb = outputs_rgb_tensor.permute(0, 2, 3, 1).numpy()\n",
        "            visualize(images_lab, outputs_rgb)\n",
        "            images_rgb = images.permute(0, 2, 3, 1).numpy()\n",
        "            outputs_rgb_flat = outputs_rgb.reshape(-1, 3)  # Reshape to 2D array\n",
        "            images_rgb_flat = images_rgb.reshape(-1, 3)    # Reshape to 2D array\n",
        "            mse_value = mse(images_rgb_flat,outputs_rgb_flat)\n",
        "            ssim_value = ssim(images,outputs_rgb, win_size=3, multichannel=True, data_range=1)\n",
        "            psnr_value = psnr(images,outputs_rgb,data_range=1)\n",
        "            print(f'MSE: {mse_value:.4f}, SSIM: {ssim_value:.4f}, PSNR: {psnr_value:.4f}')\n",
        "\n",
        "# Visualize input and reconstructed images\n",
        "def visualize(images, outputs):\n",
        "    # Visualize the first few images and their reconstructions\n",
        "    num_images = min(5, len(images))\n",
        "    fig, axes = plt.subplots(2, num_images, figsize=(12, 4))\n",
        "    for i in range(num_images):\n",
        "        image = np.clip(lab2rgb(images[i]), 0, 1)\n",
        "        axes[0, i].imshow(image)\n",
        "        axes[0, i].set_title('Input')\n",
        "        axes[0, i].axis('off')\n",
        "        output = np.clip(outputs[i], 0, 1)\n",
        "        axes[1, i].imshow(output)\n",
        "        axes[1, i].set_title('Reconstructed')\n",
        "        axes[1, i].axis('off')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# Evaluate the model\n",
        "evaluate(model_lab_to_rgb, test_dataloader)"
      ],
      "metadata": {
        "id": "dIPgvnnCfAqH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import numpy as np\n",
        "\n",
        "# 1. Extract features using the trained autoencoder\n",
        "encoder = model_lab_to_rgb.encoder.eval()  # Set to evaluation mode\n",
        "\n",
        "# 2. Define the MLP classifier\n",
        "class LABToRGBMLPClassifier(nn.Module):\n",
        "    def __init__(self, input_size, num_classes):\n",
        "        super(LABToRGBMLPClassifier, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.fc1 = nn.Linear(input_size, 128)\n",
        "        self.fc2 = nn.Linear(128, num_classes)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "writer = SummaryWriter()\n",
        "\n",
        "\n",
        "lab_to_rgb_mlp = LABToRGBMLPClassifier(input_size=100352, num_classes=2)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(lab_to_rgb_mlp.parameters(), lr=0.001)\n",
        "label_to_index = {'ants': 0, 'bees': 1}\n",
        "\n",
        "# 5. Train the MLP classifier\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    lab_to_rgb_mlp.train()  # Set model to training mode\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for inputs, labels in train_dataloader:\n",
        "        # Forward pass\n",
        "        encoder_output = encoder(inputs)\n",
        "\n",
        "        # Flatten the output\n",
        "        encoder_output_flat = encoder_output.view(encoder_output.size(0), -1)\n",
        "\n",
        "        outputs = lab_to_rgb_mlp(encoder_output_flat)\n",
        "        labels = [label_to_index[label] for label in labels]\n",
        "        labels = torch.tensor(labels)\n",
        "\n",
        "\n",
        "        # Compute loss\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Track running loss and accuracy\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    epoch_loss = running_loss / len(train_dataloader)\n",
        "    epoch_accuracy = 100 * correct / total\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.2f}%')\n",
        "    # Log metrics using Tensorboard\n",
        "    writer.add_scalar('Loss/train',epoch_loss , epoch)\n",
        "    writer.add_scalar('Accuracy/train',epoch_accuracy , epoch)\n",
        "\n",
        "    # Validate the model\n",
        "    lab_to_rgb_mlp.eval()  # Set model to evaluation mode\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_dataloader:\n",
        "            labels = [label_to_index[label] for label in labels]\n",
        "            labels = torch.tensor(labels)\n",
        "\n",
        "             # Forward pass\n",
        "            encoder_output = encoder(inputs)\n",
        "\n",
        "             # Flatten the output\n",
        "            encoder_output_flat = encoder_output.view(encoder_output.size(0), -1)\n",
        "\n",
        "            outputs = lab_to_rgb_mlp(encoder_output_flat)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    # Log validation accuracy\n",
        "    writer.add_scalar('Accuracy/val', 100 * correct / total, epoch)\n",
        "\n",
        "# 6. Use Tensorboard for visualization\n",
        "# Make sure to close the Tensorboard writer after training\n",
        "writer.close()"
      ],
      "metadata": {
        "id": "4EJ1a3OkfEn7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "zk2m6L5JfJWw",
        "outputId": "1f233c5a-f0e3-4a96-818e-ce658fc91127"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Part B'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.decomposition import PCA\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
        "from sklearn.metrics import mean_squared_error as mse\n",
        "from sklearn.metrics import mean_squared_log_error as msle\n",
        "from sklearn.metrics import mean_absolute_error as mae\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from sklearn.datasets import fetch_openml\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Define the CAE architecture\n",
        "class CAERGBTONEG(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CAERGBTONEG, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(3, 16, kernel_size=3, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Conv2d(16, 32, kernel_size=3, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.LeakyReLU(0.2)\n",
        "        )\n",
        "\n",
        "        # Decoder layers\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.ConvTranspose2d(32, 16, kernel_size=4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(16, 3, kernel_size=4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(3),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        x = self.decoder(x)\n",
        "        return x\n",
        "\n",
        "def rgb_to_negative(images):\n",
        "    negative_images = 1 - images\n",
        "    return negative_images\n",
        "\n",
        "# Initialize CAE model\n",
        "model_rgb_to_neg = CAERGBTONEG()\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model_rgb_to_neg.parameters(), lr=0.001)\n",
        "\n",
        "# Train the CAE model\n",
        "num_epochs = 30\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for images,_ in train_dataloader:\n",
        "        # Zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "        images_neg = rgb_to_negative(images)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model_rgb_to_neg(images)\n",
        "\n",
        "        # Compute the loss\n",
        "        loss = criterion(outputs, images_neg)\n",
        "\n",
        "        # Backward pass and optimize\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "\n",
        "\n",
        "    epoch_loss = running_loss / len(train_dataloader)\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f},')\n"
      ],
      "metadata": {
        "id": "k6v93WMrfNTB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from skimage.color import rgb2lab, lab2rgb\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
        "\n",
        "# Define evaluation function\n",
        "def evaluate_neg(model, dataloader):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for images, _ in dataloader:\n",
        "            outputs_neg = model(images)\n",
        "\n",
        "            images = images.permute(0, 2, 3, 1).numpy()\n",
        "            outputs_neg = outputs_neg.permute(0, 2, 3, 1).numpy()\n",
        "\n",
        "            visualize_neg(images, outputs_neg)\n",
        "\n",
        "            outputs_neg_flat = outputs_neg.reshape(-1, 3)  # Reshape to 2D array\n",
        "            images_neg_flat = rgb_to_negative(images).reshape(-1, 3)  # Reshape to 2D array\n",
        "\n",
        "            mse_value = mse(images_neg_flat,outputs_neg_flat)\n",
        "            images_neg = rgb_to_negative(images)\n",
        "\n",
        "            ssim_value = ssim(images, outputs_neg, win_size=3, data_range=1, multichannel=True)\n",
        "            psnr_value = psnr(images, outputs_neg, data_range=1)\n",
        "\n",
        "            print(f'MSE: {mse_value:.4f}, SSIM: {ssim_value:.4f}, PSNR: {psnr_value:.4f}')\n",
        "\n",
        "# Visualize input and reconstructed images\n",
        "def visualize_neg(images, outputs):\n",
        "    # Visualize the first few images and their reconstructions\n",
        "    num_images = min(5, len(images))\n",
        "    fig, axes = plt.subplots(2, num_images, figsize=(12, 4))\n",
        "    for i in range(num_images):\n",
        "        image = np.clip(images[i], 0, 1)\n",
        "        axes[0, i].imshow(image)\n",
        "        axes[0, i].set_title('Input')\n",
        "        axes[0, i].axis('off')\n",
        "        output = np.clip(outputs[i], 0, 1)\n",
        "        axes[1, i].imshow(output)\n",
        "        axes[1, i].set_title('Reconstructed')\n",
        "        axes[1, i].axis('off')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# Evaluate the model\n",
        "evaluate_neg(model_rgb_to_neg, test_dataloader)"
      ],
      "metadata": {
        "id": "M2V4qWJkfXV1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import numpy as np\n",
        "\n",
        "# 1. Extract features using the trained autoencoder\n",
        "encoder = model_rgb_to_neg.encoder.eval()  # Set to evaluation mode\n",
        "\n",
        "# 2. Define the MLP classifier\n",
        "class LABToNEGMLPClassifier(nn.Module):\n",
        "    def __init__(self, input_size, num_classes):\n",
        "        super(LABToNEGMLPClassifier, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.fc1 = nn.Linear(input_size, 128)\n",
        "        self.fc2 = nn.Linear(128, num_classes)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        #x = x.view(-1, self.input_size)\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "writer = SummaryWriter()\n",
        "\n",
        "\n",
        "rgb_to_neg_mlp = LABToNEGMLPClassifier(input_size=100352, num_classes=2)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(rgb_to_neg_mlp.parameters(), lr=0.001)\n",
        "label_to_index = {'ants': 0, 'bees': 1}\n",
        "\n",
        "# 5. Train the MLP classifier\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    rgb_to_neg_mlp.train()  # Set model to training mode\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for inputs, labels in train_dataloader:\n",
        "        # Forward pass\n",
        "        encoder_output = encoder(inputs)\n",
        "\n",
        "        # Flatten the output\n",
        "        encoder_output_flat = encoder_output.view(encoder_output.size(0), -1)\n",
        "\n",
        "        outputs = rgb_to_neg_mlp(encoder_output_flat)\n",
        "        labels = [label_to_index[label] for label in labels]\n",
        "        labels = torch.tensor(labels)\n",
        "\n",
        "\n",
        "        # Compute loss\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Track running loss and accuracy\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    epoch_loss = running_loss / len(train_dataloader)\n",
        "    epoch_accuracy = 100 * correct / total\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.2f}%')\n",
        "    # Log metrics using Tensorboard\n",
        "    writer.add_scalar('Loss/train',epoch_loss , epoch)\n",
        "    writer.add_scalar('Accuracy/train',epoch_accuracy , epoch)\n",
        "\n",
        "    # Validate the model\n",
        "    rgb_to_neg_mlp.eval()  # Set model to evaluation mode\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_dataloader:\n",
        "            labels = [label_to_index[label] for label in labels]\n",
        "            labels = torch.tensor(labels)\n",
        "\n",
        "             # Forward pass\n",
        "            encoder_output = encoder(inputs)\n",
        "\n",
        "             # Flatten the output\n",
        "            encoder_output_flat = encoder_output.view(encoder_output.size(0), -1)\n",
        "\n",
        "            outputs = rgb_to_neg_mlp(encoder_output_flat)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    # Log validation accuracy\n",
        "    writer.add_scalar('Accuracy/val', 100 * correct / total, epoch)\n",
        "\n",
        "# 6. Use Tensorboard for visualization\n",
        "# Make sure to close the Tensorboard writer after training\n",
        "writer.close()"
      ],
      "metadata": {
        "id": "3-z-U-y9fdOy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.decomposition import PCA\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
        "from sklearn.metrics import mean_squared_error as mse\n",
        "from sklearn.metrics import mean_squared_log_error as msle\n",
        "from sklearn.metrics import mean_absolute_error as mae\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from sklearn.datasets import fetch_openml\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Define the CAE architecture\n",
        "class CAERGBTOFLIP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CAERGBTOFLIP, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(3, 20, kernel_size=3, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(20),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Conv2d(20, 40, kernel_size=3, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(40),\n",
        "            nn.LeakyReLU(0.2)\n",
        "        )\n",
        "\n",
        "        # Decoder layers\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.ConvTranspose2d(40, 20, kernel_size=4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(20),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(20, 3, kernel_size=4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(3),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        x = self.decoder(x)\n",
        "        return x\n",
        "\n",
        "def horizontal_flip(images):\n",
        "    # Flip images horizontally\n",
        "    flipped_images = torch.flip(images, dims=[3])  # Flip along the width dimension (index 3)\n",
        "    return flipped_images\n",
        "\n",
        "# Initialize CAE model\n",
        "model_rgb_to_flip = CAERGBTOFLIP()\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model_rgb_to_flip.parameters(), lr=0.001)\n",
        "\n",
        "# Train the CAE model\n",
        "num_epochs = 50\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for images,_ in train_dataloader:\n",
        "        # Zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "        images_flip = horizontal_flip(images)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model_rgb_to_flip(images)\n",
        "\n",
        "        # Compute the loss\n",
        "        loss = criterion(outputs, images_flip)\n",
        "\n",
        "        # Backward pass and optimize\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "\n",
        "\n",
        "    epoch_loss = running_loss / len(train_dataloader)\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f},')\n"
      ],
      "metadata": {
        "id": "q0UNCOOsfhMr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from skimage.color import rgb2lab, lab2rgb\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
        "\n",
        "# Define evaluation function\n",
        "def evaluate_flip(model, dataloader):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for images, _ in dataloader:\n",
        "            outputs_flip = model(images)\n",
        "            images_flip = horizontal_flip(images)\n",
        "            images_flip = images_flip.permute(0, 2, 3, 1).numpy()\n",
        "\n",
        "            images = images.permute(0, 2, 3, 1).numpy()\n",
        "            outputs_flip = outputs_flip.permute(0, 2, 3, 1).numpy()\n",
        "\n",
        "            visualize_flip(images, outputs_flip)\n",
        "\n",
        "            outputs_flip_flat = outputs_flip.reshape(-1, 3)  # Reshape to 2D array\n",
        "            images_flip_flat = images_flip.reshape(-1, 3)  # Reshape to 2D array\n",
        "\n",
        "            mse_value = mse(images_flip_flat,outputs_flip_flat)\n",
        "\n",
        "\n",
        "            ssim_value = ssim(images, outputs_flip, win_size=3, data_range=1, multichannel=True)\n",
        "            psnr_value = psnr(images, outputs_flip, data_range=1)\n",
        "\n",
        "            print(f'MSE: {mse_value:.4f}, SSIM: {ssim_value:.4f}, PSNR: {psnr_value:.4f}')\n",
        "\n",
        "# Visualize input and reconstructed images\n",
        "def visualize_flip(images, outputs):\n",
        "    # Visualize the first few images and their reconstructions\n",
        "    num_images = min(5, len(images))\n",
        "    fig, axes = plt.subplots(2, num_images, figsize=(12, 4))\n",
        "    for i in range(num_images):\n",
        "        image = np.clip(images[i], 0, 1)\n",
        "        axes[0, i].imshow(image)\n",
        "        axes[0, i].set_title('Input')\n",
        "        axes[0, i].axis('off')\n",
        "        output = np.clip(outputs[i], 0, 1)\n",
        "        axes[1, i].imshow(output)\n",
        "        axes[1, i].set_title('Reconstructed')\n",
        "        axes[1, i].axis('off')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# Evaluate the model\n",
        "evaluate_flip(model_rgb_to_flip, test_dataloader)"
      ],
      "metadata": {
        "id": "g--7pq6Ffk3e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nvlT1-3jfp7o"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}